{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\vinil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\vinil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vinil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\vinil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vinil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vinil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vinil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\vinil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vinil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vinil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy scikit-learn joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1880 images belonging to 5 classes.\n",
      "Found 467 images belonging to 5 classes.\n",
      "Found 80 images belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VINIL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\VINIL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 331ms/step - accuracy: 0.5977 - loss: 1.1363 - val_accuracy: 0.7752 - val_loss: 1.1169\n",
      "Epoch 2/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 317ms/step - accuracy: 0.8731 - loss: 0.3730 - val_accuracy: 0.8073 - val_loss: 0.7004\n",
      "Epoch 3/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 323ms/step - accuracy: 0.8898 - loss: 0.3157 - val_accuracy: 0.7923 - val_loss: 1.0392\n",
      "Epoch 4/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 321ms/step - accuracy: 0.9074 - loss: 0.2898 - val_accuracy: 0.7923 - val_loss: 0.8212\n",
      "Epoch 5/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 324ms/step - accuracy: 0.9203 - loss: 0.2397 - val_accuracy: 0.7816 - val_loss: 1.0478\n",
      "Epoch 6/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 325ms/step - accuracy: 0.9192 - loss: 0.2219 - val_accuracy: 0.8030 - val_loss: 1.1206\n",
      "Epoch 7/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 324ms/step - accuracy: 0.9174 - loss: 0.2184 - val_accuracy: 0.7923 - val_loss: 1.0184\n",
      "Epoch 8/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 325ms/step - accuracy: 0.9156 - loss: 0.2151 - val_accuracy: 0.8030 - val_loss: 0.8612\n",
      "Epoch 9/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 327ms/step - accuracy: 0.9245 - loss: 0.2125 - val_accuracy: 0.7580 - val_loss: 1.0397\n",
      "Epoch 10/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 323ms/step - accuracy: 0.9381 - loss: 0.1812 - val_accuracy: 0.7645 - val_loss: 0.7891\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8102 - loss: 0.4739\n",
      "Test Accuracy: 80.00%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Data generators (unchanged)\n",
    "train_dir = r\"C:\\Users\\VINIL\\Desktop\\soil_type_pred_ML\\notebooks\\Soil Classification.v4i.folder\\train\"\n",
    "test_dir = r\"C:\\Users\\VINIL\\Desktop\\soil_type_pred_ML\\notebooks\\Soil Classification.v4i.folder\\test\"\n",
    "datagen = ImageDataGenerator(rescale=1./255,rotation_range=20,width_shift_range=0.2,height_shift_range=0.2,shear_range=0.2,zoom_range=0.2,horizontal_flip=True,validation_split=0.2)\n",
    "train_generator = datagen.flow_from_directory(train_dir,target_size=(224,224),batch_size=32,class_mode='categorical',subset=\"training\")\n",
    "val_generator = datagen.flow_from_directory(train_dir,target_size=(224,224),batch_size=32,class_mode='categorical',subset=\"validation\")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,target_size=(224,224),batch_size=32,class_mode='categorical')\n",
    "\n",
    "# Optimized model for smaller .keras file\n",
    "model = Sequential([\n",
    "    Conv2D(16,(3,3),activation='relu',input_shape=(224,224,3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(32,(3,3),activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64,(3,3),activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(64,activation='relu'),\n",
    "    Dense(5,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),metrics=['accuracy'])\n",
    "history = model.fit(train_generator,validation_data=val_generator,epochs=10,verbose=1)\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "\n",
    "# This will save a smaller .keras file\n",
    "# model.save(\"soil_classification_model.keras\")\n",
    "\n",
    "def predict_image(img_path):\n",
    "    img = image.load_img(img_path,target_size=(224,224))\n",
    "    img_array = image.img_to_array(img)/255.0\n",
    "    img_array = np.expand_dims(img_array,axis=0)\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = np.argmax(predictions)\n",
    "    print(f\"Predicted Class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:CNN model saved successfully at: C:\\Users\\VINIL\\Desktop\\soil_type_pred_ML\\flask_app\\models\\soil_cnn_model.keras\n",
      "INFO:root:Class indices saved successfully at: C:\\Users\\VINIL\\Desktop\\soil_type_pred_ML\\flask_app\\models\\class_indices.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN model and class indices saved successfully in: C:\\Users\\VINIL\\Desktop\\soil_type_pred_ML\\flask_app\\models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# ğŸ”¹ Paths Configuration\n",
    "models_folder = r\"C:\\Users\\VINIL\\Desktop\\soil_type_pred_ML\\flask_app\\models\"\n",
    "os.makedirs(models_folder, exist_ok=True)\n",
    "\n",
    "# Define file paths\n",
    "cnn_model_path = os.path.join(models_folder, \"soil_cnn_model.keras\")  # .keras instead of .h5\n",
    "class_indices_path = os.path.join(models_folder, \"class_indices.pkl\")\n",
    "\n",
    "# ğŸ”¹ Save the Trained CNN Model in Keras Format\n",
    "# Assuming you have a trained model already (named `model`)\n",
    "model.save(cnn_model_path)\n",
    "logging.info(f\"CNN model saved successfully at: {cnn_model_path}\")\n",
    "\n",
    "# ğŸ”¹ Save class indices (from your train_generator)\n",
    "# Assuming you have already loaded train_generator and it has class_indices\n",
    "with open(class_indices_path, \"wb\") as ci_file:\n",
    "    pickle.dump(train_generator.class_indices, ci_file)\n",
    "logging.info(f\"Class indices saved successfully at: {class_indices_path}\")\n",
    "\n",
    "print(\"CNN model and class indices saved successfully in:\", models_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
